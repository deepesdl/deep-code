{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":"<p><code>deep-code</code> is a lightweight Python CLI and API that publishes DeepESDL datasets and workflows as EarthCODE Open Science Catalog metadata. It can generate starter configs, build STAC collections and OGC API records, and open pull requests to the target EarthCODE metadata repository (production, staging, or testing).</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Generate starter dataset and workflow YAML templates.</li> <li>Publish dataset collections, workflows, and experiments via a single command.</li> <li>Build STAC collections and catalogs for Datasets and their corresponding variables automatically from the dataset metadata.</li> <li>Build OGC API records for Workflows and Experiments from your configs.</li> <li>Flexible publishling targets i.e production/staging/testing EarthCODE metadata repositories with GitHub automation.</li> </ul> <pre><code>%%{init: {'flowchart': {'nodeSpacing': 110, 'rankSpacing': 160}, 'themeVariables': {'fontSize': '28px', 'lineHeight': '1.6em'}}}%%\nflowchart LR\n    subgraph User\n        A[\"Config files&lt;br/&gt;(dataset.yaml, workflow.yaml)\"]\n        B[\"deep-code CLI&lt;br/&gt;(generate-config, publish)\"]\n    end\n\n    subgraph App[\"deep-code internals\"]\n        C[\"Publisher&lt;br/&gt;(mode: dataset/workflow/all)\"]\n        D[\"STAC builder&lt;br/&gt;OscDatasetStacGenerator\"]\n        E[\"OGC record builder&lt;br/&gt;OSCWorkflowOGCApiRecordGenerator\"]\n        F[\"GitHubAutomation&lt;br/&gt;(fork, clone, branch, PR)\"]\n    end\n\n    subgraph Output\n        G[\"Generated JSON&lt;br/&gt;collections, variables,&lt;br/&gt;workflows, experiments\"]\n        H[\"GitHub PR&lt;br/&gt;(prod/staging/testing repo)\"]\n        I[\"EarthCODE Open Science Catalog\"]\n    end\n\n    A --&gt; B --&gt; C\n    C --&gt; D\n    C --&gt; E\n    D --&gt; G\n    E --&gt; G\n    G --&gt; F --&gt; H --&gt; I</code></pre>"},{"location":"about/","title":"About","text":""},{"location":"about/#changelog","title":"Changelog","text":"<p>See <code>CHANGES.md</code>.</p>"},{"location":"about/#reporting-issues","title":"Reporting issues","text":"<p>Open an issue at https://github.com/deepesdl/deep-code/issues.</p>"},{"location":"about/#contributions","title":"Contributions","text":"<p>PRs are welcome. Please follow the code style (black/ruff) and add tests where relevant.</p>"},{"location":"about/#development-install","title":"Development install","text":"<pre><code>pip install -e .[dev]\npytest\npytest --cov=deep-code\nblack .\nruff check .\n</code></pre>"},{"location":"about/#documentation-commands-mkdocs","title":"Documentation commands (MkDocs)","text":"<pre><code>pip install -e .[docs]      # install mkdocs + theme\nmkdocs serve                # live preview at http://127.0.0.1:8000\nmkdocs build                # build site into site/\nmkdocs gh-deploy --clean    # publish to GitHub Pages\n</code></pre>"},{"location":"about/#license","title":"License","text":"<p>MIT License. See <code>LICENSE</code>.</p>"},{"location":"cli/","title":"CLI","text":""},{"location":"cli/#generate-configs","title":"Generate configs","text":"<p>Create starter templates for both workflow and dataset:</p> <pre><code>deep-code generate-config                 # writes to current directory\ndeep-code generate-config -o ./configs    # custom output folder\n</code></pre>"},{"location":"cli/#publish-metadata","title":"Publish metadata","text":"<p>Publish dataset, workflow, or both (default is both) to the target environment:</p> <pre><code>deep-code publish dataset.yaml workflow.yaml                 # production (default)\ndeep-code publish dataset.yaml workflow.yaml -e staging      # staging\ndeep-code publish dataset.yaml -m dataset                    # dataset only\ndeep-code publish workflow.yaml -m workflow                  # workflow only\ndeep-code publish --dataset-config ./ds.yaml --workflow-config ./wf.yaml -m all\n</code></pre> <p>Options: - <code>--environment/-e</code>: <code>production</code> (default) | <code>staging</code> | <code>testing</code> - <code>--mode/-m</code>: <code>all</code> (default) | <code>dataset</code> | <code>workflow</code> - <code>--dataset-config</code> / <code>--workflow-config</code>: explicitly set paths and bypass auto-detection</p>"},{"location":"cli/#how-publishing-works","title":"How publishing works","text":"<ol> <li>Reads your configs and builds dataset STAC collections plus variable catalogs.</li> <li>Builds workflow and experiment OGC API Records.</li> <li>Forks/clones the target metadata repo (production, staging, or testing), commits generated JSON, and opens a pull request on your behalf.</li> </ol>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#dataset-config-yaml","title":"Dataset config (YAML)","text":"<pre><code>dataset_id: your-dataset.zarr\ncollection_id: your-collection\nosc_themes: [cryosphere]\nosc_region: global\ndataset_status: completed   # or ongoing/planned\ndocumentation_link: https://example.com/docs\naccess_link: s3://bucket/your-dataset.zarr\n</code></pre>"},{"location":"configuration/#workflow-config-yaml","title":"Workflow config (YAML)","text":"<pre><code>workflow_id: your-workflow\nproperties:\n  title: \"My workflow\"\n  description: \"What this workflow does\"\n  keywords: [\"Earth Science\"]\n  themes: [\"cryosphere\"]\n  license: proprietary\n  jupyter_kernel_info:\n    name: deepesdl-xcube-1.8.3\n    python_version: 3.11\n    env_file: https://example.com/environment.yml\njupyter_notebook_url: https://github.com/org/repo/path/to/notebook.ipynb\ncontact:\n  - name: Jane Doe\n    organization: Example Org\n    links:\n      - rel: about\n        type: text/html\n        href: https://example.org\n</code></pre> <p>More templates and examples live in <code>dataset_config.yaml</code>, <code>workflow_config.yaml</code>, and <code>example-config/</code>.</p>"},{"location":"examples/","title":"Examples","text":"<ul> <li>Templates: <code>dataset_config.yaml</code>, <code>workflow_config.yaml</code></li> <li>Example configs: <code>examples/example-config/</code></li> <li>Notebooks on publishing: <code>examples/notebooks</code> </li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>When working with cloud platforms like DeepESDL, workflow outputs typically live in S3 object storage. Before the project ends or once datasets and workflows are finalized, move the datasets into the ESA Project Results Repository (PRR) and publish the workflows (Jupyter notebooks) to a publicly accessible GitHub repository. The notebook path becomes an input in the dataset config file.</p> <p>Use the EarthCODE Project Results Repository to publish and preserve outputs from ESA-funded Earth observation projects. It is professionally maintained, FAIR-aligned, and keeps your results findable, reusable, and citable for the long term\u2014no storage, operations, or access headaches.</p> <p>To transfer datasets into the ESA PRR, contact the DeepESDL platform team at esdl-support@brockmann-consult.de.</p> <p>In the near future, <code>deep-code</code> will include built-in support for uploading your results to the ESA PRR as part of the publishing workflow, making it seamless to share your scientific contributions with the community.</p>"},{"location":"getting-started/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+</li> <li>GitHub token with access to the target EarthCODE metadata repo.</li> <li>Input configuration files.</li> <li>Datasets which needs to be published is uploaded to S3 like object storage and made publicly accessible.</li> </ul>"},{"location":"getting-started/#install","title":"Install","text":"<pre><code>pip install deep-code\n</code></pre>"},{"location":"getting-started/#authentication","title":"Authentication","text":"<p>The CLI or the Python API reads GitHub credentials from a <code>.gitaccess</code> file in the directory where you run the command:</p> <ol> <li> <p>Generate a GitHub Personal Access Token (PAT)</p> <ol> <li>Navigate to GitHub \u2192 Settings \u2192 Developer settings \u2192 Personal access tokens.</li> <li>Click \u201cGenerate new token\u201d.</li> <li>Choose the following scopes to ensure full access:<ul> <li>repo (Full control of repositories \u2014 includes fork, pull, push, and read)</li> </ul> </li> <li>Generate the token and copy it immediately \u2014 GitHub won\u2019t show it again.</li> </ol> </li> <li> <p>Create the .gitaccess File</p> <p>Create a plain text file named .gitaccess in your project directory or home folder:</p> <p><pre><code>github-username: your-git-user\ngithub-token: your-personal-access-token\n</code></pre> Replace your-git-user and your-personal-access-token with your actual GitHub username and token.</p> </li> </ol>"},{"location":"python-api/","title":"Python API","text":"<p><code>deep_code.tools.publish.Publisher</code> is the main entry point.</p> <pre><code>from deep_code.tools.publish import Publisher\n\npublisher = Publisher(\n    dataset_config_path=\"dataset.yaml\",\n    workflow_config_path=\"workflow.yaml\",\n    environment=\"staging\",\n)\n\n# Generate files locally (no PR)\npublisher.publish(write_to_file=True, mode=\"all\")\n\n# Or open a PR directly\npublisher.publish(write_to_file=False, mode=\"dataset\")\n</code></pre>"}]}